{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides a Collaborative Filtering (CF) Implementation, Training, and Testing:\n",
    "\n",
    "1. Data Collection, Processing, Splitting into Train/Test\n",
    "2. Model Building\n",
    "3. Training CF Model on Custom Objective Functions\n",
    "4. Evaluating Different Objective Functions\n",
    "5. Extra Stuff: Item-Item CF and more. (If Time Permits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data Collection, Processing, Splitting into Train/Test** \\\n",
    "The goal of this section is to process the dataset in \"/dataset/ratings\". \\\n",
    "70% of the resulting data is put into the training matrix and the remaining 30% is held in the testing matrix. \\\n",
    "Each movie and user is sequentially assigned an ID that becomes their matrix index as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "data_df = pd.read_csv('./dataset/ratings.dat', sep=',', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], engine='python')\n",
    "\n",
    "# Filter out only the first 2000 users and first 2000 movies\n",
    "data_df = data_df[data_df['UserID'] <= 2000]\n",
    "data_df = data_df[data_df['MovieID'] <= 2000]\n",
    "\n",
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_MovieID = data_df['MovieID'].unique()\n",
    "unique_UserID = data_df['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "movie_old2new_id_dict = dict()\n",
    "for i in unique_MovieID:\n",
    "    movie_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "    \n",
    "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "user_list = data_df['UserID'].values\n",
    "movie_list = data_df['MovieID'].values\n",
    "for j in range(len(data_df)):\n",
    "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
    "    movie_list[j] = movie_old2new_id_dict[movie_list[j]]\n",
    "data_df['UserID'] = user_list\n",
    "data_df['movieID'] = movie_list\n",
    "\n",
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "np.random.seed(0)\n",
    "train_index = np.random.random(len(data_df)) <= 0.7\n",
    "train_df = data_df[train_index]\n",
    "test_df = data_df[~train_index]\n",
    "\n",
    "# generate train_mat and test_mat\n",
    "num_user = len(data_df['UserID'].unique())\n",
    "num_movie = len(data_df['MovieID'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float)\n",
    "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This marks the termination of the data collection and processing step.\n",
    "We have 2 matrices, $train\\_mat$ and $test\\_mat$. \\\n",
    "Both matrices have the dimensions: Number of Users $\\times$ Number of Movies or $numU \\times numM$ \\\n",
    "where $train\\_mat[i][j]$ or $test\\_mat[i][j]$ is user i's rating for movie j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we move to section 2: Model Building** and **section 3: Training CF Model on Custom Objective Functions** \\\n",
    "In order to build the model, we need to encode the information into 2 low rank matrices, such that \\\n",
    "\n",
    "$ R = UM $, where $U$ is the user matrix and and $M$ is the movie matrix, \\\n",
    "whose dimensions are $numU \\times k$ and $k \\times numM$ respectively, where $k << min\\{numU, numM\\}$ \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function: cosine_sim, Performance metric: 0.23621863841552873\n",
      "Objective function: cosine_sim, Performance metric: 0.23621824458436688\n",
      "Objective function: cosine_sim, Performance metric: 0.23621779548066899\n",
      "Objective function: cosine_sim, Performance metric: 0.23621745844544315\n",
      "Objective function: cosine_sim, Performance metric: 0.23621702855617094\n",
      "Objective function: cosine_sim, Performance metric: 0.23621677153576945\n",
      "Objective function: cosine_sim, Performance metric: 0.23621623337369677\n",
      "Objective function: cosine_sim, Performance metric: 0.23620524599965093\n",
      "Objective function: cosine_sim, Performance metric: 0.23620496691722134\n",
      "Objective function: cosine_sim, Performance metric: 0.2362046661569779\n",
      "Objective function: cosine_sim, Performance metric: 0.2362040427256708\n",
      "Objective function: cosine_sim, Performance metric: 0.23620347483073748\n",
      "Objective function: cosine_sim, Performance metric: 0.2362033059310345\n",
      "Objective function: cosine_sim, Performance metric: 0.23620276476484509\n",
      "Objective function: cosine_sim, Performance metric: 0.23620251691384833\n",
      "Objective function: cosine_sim, Performance metric: 0.23620109073947726\n",
      "Objective function: cosine_sim, Performance metric: 0.23620084531572516\n",
      "Objective function: cosine_sim, Performance metric: 0.23620062325151406\n",
      "Objective function: cosine_sim, Performance metric: 0.2362003766206588\n",
      "Objective function: cosine_sim, Performance metric: 0.2362001541396614\n",
      "Objective function: cosine_sim, Performance metric: 0.23619966603218645\n",
      "Objective function: cosine_sim, Performance metric: 0.2361992279089846\n",
      "Objective function: cosine_sim, Performance metric: 0.2361989330192316\n",
      "Objective function: cosine_sim, Performance metric: 0.23619866818072327\n",
      "Objective function: cosine_sim, Performance metric: 0.2361983641851661\n",
      "Objective function: cosine_sim, Performance metric: 0.23619761104386922\n",
      "Objective function: cosine_sim, Performance metric: 0.23619663375093922\n",
      "Objective function: cosine_sim, Performance metric: 0.23619644635618456\n",
      "Objective function: cosine_sim, Performance metric: 0.23619600239342467\n",
      "Objective function: cosine_sim, Performance metric: 0.23619548126653964\n",
      "Objective function: cosine_sim, Performance metric: 0.23619507138232318\n",
      "Objective function: cosine_sim, Performance metric: 0.236194156586303\n",
      "Objective function: cosine_sim, Performance metric: 0.23619357485256004\n",
      "Objective function: cosine_sim, Performance metric: 0.23619355929106575\n",
      "Objective function: cosine_sim, Performance metric: 0.2361914481466169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 115>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m objective_functions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine_sim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m objective_func \u001b[38;5;129;01min\u001b[39;00m objective_functions:\n\u001b[1;32m--> 116\u001b[0m     user_features, movie_features \u001b[38;5;241m=\u001b[39m \u001b[43mcollaborative_filtering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_latent_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnuclear_norm_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     performance_metric \u001b[38;5;241m=\u001b[39m evaluate_model(test_mat, user_features, movie_features, objective_func\u001b[38;5;241m=\u001b[39mobjective_func)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjective function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective_func\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Performance metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperformance_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mcollaborative_filtering\u001b[1;34m(train_mat, num_latent_features, num_iterations, learning_rate, reg_param, nuclear_norm_param, objective_func)\u001b[0m\n\u001b[0;32m     64\u001b[0m         user_features[user_id] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m user_grad\n\u001b[0;32m     65\u001b[0m         movie_features[movie_id] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m movie_grad\n\u001b[1;32m---> 67\u001b[0m         performance_metric \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjective function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective_func\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Performance metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperformance_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_features, movie_features\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(test_mat, user_features, movie_features, objective_func)\u001b[0m\n\u001b[0;32m    100\u001b[0m movie_vec_norm \u001b[38;5;241m=\u001b[39m movie_vec \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(movie_vec)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_vec_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_vec_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Calculate error based on cosine similarity\u001b[39;00m\n\u001b[0;32m    106\u001b[0m errors[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine_sim\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def collaborative_filtering(train_mat, num_latent_features=10, num_iterations=50, learning_rate=0.001, reg_param=0.02, nuclear_norm_param=0.01, objective_func='mse'):\n",
    "    \"\"\"\n",
    "    Implement collaborative filtering with different objective functions and nuclear norm regularization.\n",
    "\n",
    "    Args:\n",
    "        train_mat (scipy.coo_matrix): The training matrix with user ratings for movies.\n",
    "        num_latent_features (int): The number of latent features to use in the low-rank approximation.\n",
    "        num_iterations (int): The number of iterations to perform during optimization.\n",
    "        learning_rate (float): The learning rate for gradient descent optimization.\n",
    "        reg_param (float): The regularization parameter to prevent overfitting.\n",
    "        nuclear_norm_param (float): The nuclear norm regularization parameter to encourage low-rank interpretations.\n",
    "        objective_func (str): The objective function to use ('mse', 'mae', 'logistic', 'nuclear_norm', or 'cosine_sim').\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: User latent feature matrix.\n",
    "        numpy.ndarray: Movie latent feature matrix.\n",
    "    \"\"\"\n",
    "    num_users, num_movies = train_mat.shape\n",
    "    \n",
    "    # Initialize user and movie latent feature matrices\n",
    "    user_features = np.random.rand(num_users, num_latent_features)\n",
    "    movie_features = np.random.rand(num_movies, num_latent_features)\n",
    "    \n",
    "    users = train_mat.row\n",
    "    movies = train_mat.col\n",
    "    ratings = train_mat.data\n",
    "    num_pts = len(users)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(num_pts):\n",
    "            user_id, movie_id, rating = users[i], movies[i], ratings[i]\n",
    "            predicted_rating = np.dot(user_features[user_id], movie_features[movie_id])\n",
    "            error = rating - predicted_rating\n",
    "    \n",
    "            # Update user and movie latent feature vectors based on the objective function\n",
    "            if objective_func == 'mse':\n",
    "                user_grad = -error * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                movie_grad = -error * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "            elif objective_func == 'mae':\n",
    "                user_grad = -np.sign(error) * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                movie_grad = -np.sign(error) * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "            elif objective_func == 'logistic':\n",
    "                coeff = (1-rating)/(1-predicted_rating) - rating/predicted_rating\n",
    "                user_grad = coeff * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                movie_grad = coeff * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "            elif objective_func == 'nuclear_norm':\n",
    "                user_grad = -error * movie_features[movie_id] + reg_param * user_features[user_id] + 2 * nuclear_norm_param * np.linalg.norm(user_features[user_id], ord=1)\n",
    "                movie_grad = -error * user_features[user_id] + reg_param * movie_features[movie_id] + 2 * nuclear_norm_param * np.linalg.norm(movie_features[movie_id], ord=1)\n",
    "            elif objective_func == 'cosine_sim':\n",
    "                user_vec = user_features[user_id]\n",
    "                movie_vec = movie_features[movie_id]\n",
    "                \n",
    "                # Normalize user and movie vectors\n",
    "                user_vec_norm = user_vec / np.linalg.norm(user_vec)\n",
    "                movie_vec_norm = movie_vec / np.linalg.norm(movie_vec)\n",
    "                                \n",
    "                # Calculate gradients\n",
    "                user_grad = -movie_vec_norm / (np.linalg.norm(user_vec) * np.linalg.norm(movie_vec))\n",
    "                movie_grad = -user_vec_norm / (np.linalg.norm(user_vec) * np.linalg.norm(movie_vec))    \n",
    "            \n",
    "            user_features[user_id] -= learning_rate * user_grad\n",
    "            movie_features[movie_id] -= learning_rate * movie_grad\n",
    "            \n",
    "    return user_features, movie_features\n",
    "\n",
    "def evaluate_model(test_mat, user_features, movie_features, objective_func='mse'):\n",
    "    \"\"\"\n",
    "    Evaluate the collaborative filtering model on the test data with different objective functions.\n",
    "    \"\"\"\n",
    "    users = test_mat.row\n",
    "    movies = test_mat.col\n",
    "    ratings = test_mat.data\n",
    "    num_pts = len(users)\n",
    "    errors = np.empty(num_pts)\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        user_id, movie_id, actual_rating = users[i], movies[i], ratings[i]\n",
    "        predicted_rating = np.dot(user_features[user_id], movie_features[movie_id])\n",
    "\n",
    "        if objective_func == 'mse':\n",
    "            errors[i] = (actual_rating - predicted_rating) ** 2\n",
    "        elif objective_func == 'mae':\n",
    "            errors[i] = abs(actual_rating - predicted_rating)\n",
    "        elif objective_func == 'logistic':\n",
    "            errors[i] = -actual_rating * np.log(predicted_rating) - (1 - actual_rating) * np.log(1 - predicted_rating)\n",
    "        elif objective_func == 'nuclear_norm':\n",
    "            errors[i] = (actual_rating - predicted_rating) ** 2\n",
    "        elif objective_func == 'cosine_sim':\n",
    "            user_vec = user_features[user_id]\n",
    "            movie_vec = movie_features[movie_id]\n",
    "            \n",
    "            # Normalize user and movie vectors\n",
    "            user_vec_norm = user_vec / np.linalg.norm(user_vec)\n",
    "            movie_vec_norm = movie_vec / np.linalg.norm(movie_vec)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            cosine_sim = np.dot(user_vec_norm, movie_vec_norm)\n",
    "            \n",
    "            # Calculate error based on cosine similarity\n",
    "            errors[i] = 1 - cosine_sim\n",
    "\n",
    "    if objective_func == 'mse' or objective_func == 'nuclear_norm':\n",
    "        return np.sqrt(np.mean(errors))\n",
    "    elif objective_func == 'mae' or objective_func == 'logistic' or objective_func == 'cosine_sim':\n",
    "        return np.mean(errors)\n",
    "\n",
    "objective_functions = ['mse', 'mae', 'logistic', 'nuclear_norm', 'cosine_sim']\n",
    "\n",
    "for objective_func in objective_functions:\n",
    "    user_features, movie_features = collaborative_filtering(train_mat, num_latent_features=5, num_iterations=25, learning_rate=0.001, reg_param=0.01, nuclear_norm_param=0.001, objective_func=objective_func)\n",
    "    performance_metric = evaluate_model(test_mat, user_features, movie_features, objective_func=objective_func)\n",
    "    print(f\"Objective function: {objective_func}, Performance metric: {performance_metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
