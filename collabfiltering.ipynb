{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides a Collaborative Filtering (CF) Implementation, Training, and Testing:\n",
    "\n",
    "1. Data Collection, Processing, Splitting into Train/Test\n",
    "2. Model Building\n",
    "3. Training CF Model on Custom Objective Functions\n",
    "4. Evaluating Different Objective Functions\n",
    "5. Extra Stuff: Item-Item CF and more. (If Time Permits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data Collection, Processing, Splitting into Train/Test** \\\n",
    "The goal of this section is to process the dataset in \"/dataset/ratings\". \\\n",
    "70% of the resulting data is put into the training matrix and the remaining 30% is held in the testing matrix. \\\n",
    "Each movie and user is sequentially assigned an ID that becomes their matrix index as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "data_df = pd.read_csv('./dataset/ratings.dat', sep=',', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], engine='python')\n",
    "\n",
    "# Filter out only the first 500 users and first 500 movies\n",
    "data_df = data_df[data_df['UserID'] <= 500]\n",
    "data_df = data_df[data_df['MovieID'] <= 500]\n",
    "\n",
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_MovieID = data_df['MovieID'].unique()\n",
    "unique_UserID = data_df['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "movie_old2new_id_dict = dict()\n",
    "for i in unique_MovieID:\n",
    "    movie_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "    \n",
    "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "user_list = data_df['UserID'].values\n",
    "movie_list = data_df['MovieID'].values\n",
    "for j in range(len(data_df)):\n",
    "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
    "    movie_list[j] = movie_old2new_id_dict[movie_list[j]]\n",
    "data_df['UserID'] = user_list\n",
    "data_df['movieID'] = movie_list\n",
    "\n",
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "np.random.seed(0)\n",
    "train_index = np.random.random(len(data_df)) <= 0.7\n",
    "train_df = data_df[train_index]\n",
    "test_df = data_df[~train_index]\n",
    "\n",
    "# generate train_mat and test_mat\n",
    "num_user = len(data_df['UserID'].unique())\n",
    "num_movie = len(data_df['MovieID'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()\n",
    "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This marks the termination of the data collection and processing step.\n",
    "We have 2 matrices, $train\\_mat$ and $test\\_mat$. \\\n",
    "Both matrices have the dimensions: Number of Users $\\times$ Number of Movies or $numU \\times numM$ \\\n",
    "where $train\\_mat[i][j]$ or $test\\_mat[i][j]$ is user i's rating for movie j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we move to section 2: Model Building** and **section 3: Training CF Model on Custom Objective Functions** \\\n",
    "In order to build the model, we need to encode the information into 2 low rank matrices, such that \\\n",
    "\n",
    "$ R = UM $, where $U$ is the user matrix and and $M$ is the movie matrix, \\\n",
    "whose dimensions are $numU \\times k$ and $k \\times numM$ respectively, where $k << min\\{numU, numM\\}$ \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def collaborative_filtering(train_mat, num_latent_features=10, num_iterations=50, learning_rate=0.001, reg_param=0.02, nuclear_norm_param=0.01, objective_func='mse'):\n",
    "    \"\"\"\n",
    "    Implement collaborative filtering with different objective functions and nuclear norm regularization.\n",
    "\n",
    "    Args:\n",
    "        train_mat (numpy.ndarray): The training matrix with user ratings for movies.\n",
    "        num_latent_features (int): The number of latent features to use in the low-rank approximation.\n",
    "        num_iterations (int): The number of iterations to perform during optimization.\n",
    "        learning_rate (float): The learning rate for gradient descent optimization.\n",
    "        reg_param (float): The regularization parameter to prevent overfitting.\n",
    "        nuclear_norm_param (float): The nuclear norm regularization parameter to encourage low-rank interpretations.\n",
    "        objective_func (str): The objective function to use ('mse', 'mae', 'logistic', or 'nuclear_norm').\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: User latent feature matrix.\n",
    "        numpy.ndarray: Movie latent feature matrix.\n",
    "    \"\"\"\n",
    "    num_users, num_movies = train_mat.shape\n",
    "\n",
    "    # Initialize user and movie latent feature matrices\n",
    "    user_features = np.random.rand(num_users, num_latent_features)\n",
    "    movie_features = np.random.rand(num_movies, num_latent_features)\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"Iteration {iteration}\")\n",
    "        for user_id in range(num_users):\n",
    "            for movie_id in range(num_movies):\n",
    "                if not train_mat[user_id, movie_id] != 0:\n",
    "                    rating = train_mat[user_id, movie_id]\n",
    "                    predicted_rating = np.dot(user_features[user_id], movie_features[movie_id])\n",
    "                    error = rating - predicted_rating\n",
    "\n",
    "                    # Update user and movie latent feature vectors based on the objective function\n",
    "                    if objective_func == 'mse':\n",
    "                        user_grad = -2 * error * movie_features[movie_id] + 2 * reg_param * user_features[user_id]\n",
    "                        movie_grad = -2 * error * user_features[user_id] + 2 * reg_param * movie_features[movie_id]\n",
    "                    elif objective_func == 'mae':\n",
    "                        user_grad = -np.sign(error) * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                        movie_grad = -np.sign(error) * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "                    elif objective_func == 'logistic':\n",
    "                        predicted_rating = 1 / (1 + np.exp(-predicted_rating))\n",
    "                        user_grad = (predicted_rating - rating) * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                        movie_grad = (predicted_rating - rating) * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "                    elif objective_func == 'nuclear_norm':\n",
    "                        user_grad = -2 * error * movie_features[movie_id] + 2 * reg_param * user_features[user_id] + 2 * nuclear_norm_param * np.linalg.norm(user_features[user_id], ord=1)\n",
    "                        movie_grad = -2 * error * user_features[user_id] + 2 * reg_param * movie_features[movie_id] + 2 * nuclear_norm_param * np.linalg.norm(movie_features[movie_id], ord=1)\n",
    "\n",
    "                    user_features[user_id] -= learning_rate * user_grad\n",
    "                    movie_features[movie_id] -= learning_rate * movie_grad\n",
    "\n",
    "    return user_features, movie_features\n",
    "\n",
    "def evaluate_model(train_mat, test_mat, user_features, movie_features, objective_func='mse'):\n",
    "    \"\"\"\n",
    "    Evaluate the collaborative filtering model on the test data with different objective functions.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for user_id in range(test_mat.shape[0]):\n",
    "        for movie_id in range(test_mat.shape[1]):\n",
    "            if not np.isnan(test_mat[user_id, movie_id]):\n",
    "                actual_rating = test_mat[user_id, movie_id]\n",
    "                predicted_rating = np.dot(user_features[user_id], movie_features[movie_id])\n",
    "\n",
    "                if objective_func == 'mse':\n",
    "                    error = (actual_rating - predicted_rating) ** 2\n",
    "                elif objective_func == 'mae':\n",
    "                    error = abs(actual_rating - predicted_rating)\n",
    "                elif objective_func == 'logistic':\n",
    "                    predicted_rating = 1 / (1 + np.exp(-predicted_rating))\n",
    "                    error = -actual_rating * np.log(predicted_rating) - (1 - actual_rating) * np.log(1 - predicted_rating)\n",
    "                elif objective_func == 'nuclear_norm':\n",
    "                    error = (actual_rating - predicted_rating) ** 2\n",
    "\n",
    "                errors.append(error)\n",
    "\n",
    "    if objective_func == 'mse' or objective_func == 'nuclear_norm':\n",
    "        return np.sqrt(np.mean(errors))\n",
    "    elif objective_func == 'mae':\n",
    "        return np.mean(errors)\n",
    "    elif objective_func == 'logistic':\n",
    "        return np.mean(errors)\n",
    "\n",
    "objective_functions = ['mse', 'mae', 'logistic', 'nuclear_norm']\n",
    "\n",
    "for objective_func in objective_functions:\n",
    "    user_features, movie_features = collaborative_filtering(train_mat, num_latent_features=5, num_iterations=100, learning_rate=0.001, reg_param=0.01, nuclear_norm_param=0.001, objective_func=objective_func)\n",
    "    performance_metric = evaluate_model(train_mat, test_mat, user_features, movie_features, objective_func=objective_func)\n",
    "    print(f\"Objective function: {objective_func}, Performance metric: {performance_metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
