{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides a Collaborative Filtering (CF) Implementation, Training, and Testing:\n",
    "\n",
    "1. Data Collection, Processing, Splitting into Train/Test\n",
    "2. Model Building\n",
    "3. Training CF Model on Custom Objective Functions\n",
    "4. Evaluating Different Objective Functions\n",
    "5. Extra Stuff: Item-Item CF and more. (If Time Permits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data Collection, Processing, Splitting into Train/Test** \\\n",
    "The goal of this section is to process the dataset in \"/dataset/ratings\". \\\n",
    "70% of the resulting data is put into the training matrix and the remaining 30% is held in the testing matrix. \\\n",
    "Each movie and user is sequentially assigned an ID that becomes their matrix index as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "data_df = pd.read_csv('./dataset/ratings.dat', sep=',', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], engine='python')\n",
    "\n",
    "# Filter out only the first 2000 users and first 2000 movies\n",
    "data_df = data_df[data_df['UserID'] <= 2000]\n",
    "data_df = data_df[data_df['MovieID'] <= 2000]\n",
    "\n",
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_MovieID = data_df['MovieID'].unique()\n",
    "unique_UserID = data_df['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "movie_old2new_id_dict = dict()\n",
    "for i in unique_MovieID:\n",
    "    movie_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "    \n",
    "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "user_list = data_df['UserID'].values\n",
    "movie_list = data_df['MovieID'].values\n",
    "for j in range(len(data_df)):\n",
    "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
    "    movie_list[j] = movie_old2new_id_dict[movie_list[j]]\n",
    "data_df['UserID'] = user_list\n",
    "data_df['movieID'] = movie_list\n",
    "\n",
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "np.random.seed(0)\n",
    "train_index = np.random.random(len(data_df)) <= 0.7\n",
    "train_df = data_df[train_index]\n",
    "test_df = data_df[~train_index]\n",
    "\n",
    "# generate train_mat and test_mat\n",
    "num_user = len(data_df['UserID'].unique())\n",
    "num_movie = len(data_df['MovieID'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float)\n",
    "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This marks the termination of the data collection and processing step.\n",
    "We have 2 matrices, $train\\_mat$ and $test\\_mat$. \\\n",
    "Both matrices have the dimensions: Number of Users $\\times$ Number of Movies or $numU \\times numM$ \\\n",
    "where $train\\_mat[i][j]$ or $test\\_mat[i][j]$ is user i's rating for movie j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we move to section 2: Model Building** and **section 3: Training CF Model on Custom Objective Functions** \\\n",
    "In order to build the model, we need to encode the information into 2 low rank matrices, such that \\\n",
    "\n",
    "$ R = UM $, where $U$ is the user matrix and and $M$ is the movie matrix, \\\n",
    "whose dimensions are $numU \\times k$ and $k \\times numM$ respectively, where $k << min\\{numU, numM\\}$ \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function: mse, Performance metric: 0.9321173249736074\n",
      "Objective function: mae, Performance metric: 0.7496321478844447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colby\\AppData\\Local\\Temp\\ipykernel_24124\\2030398574.py:91: RuntimeWarning: invalid value encountered in log\n",
      "  errors[i] = -actual_rating * np.log(predicted_rating) - (1 - actual_rating) * np.log(1 - predicted_rating)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function: logistic, Performance metric: nan\n",
      "Objective function: nuclear_norm, Performance metric: 0.9337504766447862\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def collaborative_filtering(train_mat, num_latent_features=10, num_iterations=50, learning_rate=0.001, reg_param=0.02, nuclear_norm_param=0.01, objective_func='mse'):\n",
    "    \"\"\"\n",
    "    Implement collaborative filtering with different objective functions and nuclear norm regularization.\n",
    "\n",
    "    Args:\n",
    "        train_mat (scipy.coo_matrix): The training matrix with user ratings for movies.\n",
    "        num_latent_features (int): The number of latent features to use in the low-rank approximation.\n",
    "        num_iterations (int): The number of iterations to perform during optimization.\n",
    "        learning_rate (float): The learning rate for gradient descent optimization.\n",
    "        reg_param (float): The regularization parameter to prevent overfitting.\n",
    "        nuclear_norm_param (float): The nuclear norm regularization parameter to encourage low-rank interpretations.\n",
    "        objective_func (str): The objective function to use ('mse', 'mae', 'logistic', 'nuclear_norm', or 'cosine_sim').\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: User latent feature matrix.\n",
    "        numpy.ndarray: Movie latent feature matrix.\n",
    "    \"\"\"\n",
    "    num_users, num_movies = train_mat.shape\n",
    "    \n",
    "    # Initialize user and movie latent feature matrices\n",
    "    user_features = np.random.rand(num_users, num_latent_features)\n",
    "    movie_features = np.random.rand(num_movies, num_latent_features)\n",
    "    \n",
    "    users = train_mat.row\n",
    "    movies = train_mat.col\n",
    "    ratings = train_mat.data\n",
    "    num_pts = len(users)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(num_pts):\n",
    "            user_id, movie_id, rating = users[i], movies[i], ratings[i]\n",
    "            predicted_rating = np.dot(user_features[user_id], movie_features[movie_id])\n",
    "            error = rating - predicted_rating\n",
    "    \n",
    "            # Update user and movie latent feature vectors based on the objective function\n",
    "            if objective_func == 'mse':\n",
    "                user_grad = -error * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                movie_grad = -error * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "            elif objective_func == 'mae':\n",
    "                user_grad = -np.sign(error) * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                movie_grad = -np.sign(error) * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "            elif objective_func == 'logistic':\n",
    "                coeff = (1-rating)/(1-predicted_rating) - rating/predicted_rating\n",
    "                user_grad = coeff * movie_features[movie_id] + reg_param * user_features[user_id]\n",
    "                movie_grad = coeff * user_features[user_id] + reg_param * movie_features[movie_id]\n",
    "            elif objective_func == 'nuclear_norm':\n",
    "                user_grad = -error * movie_features[movie_id] + reg_param * user_features[user_id] + 2 * nuclear_norm_param * np.linalg.norm(user_features[user_id], ord=1)\n",
    "                movie_grad = -error * user_features[user_id] + reg_param * movie_features[movie_id] + 2 * nuclear_norm_param * np.linalg.norm(movie_features[movie_id], ord=1)\n",
    "            elif objective_func == 'cosine_sim':\n",
    "                user_vec = user_features[user_id]\n",
    "                movie_vec = movie_features[movie_id]\n",
    "                \n",
    "                # Normalize user and movie vectors\n",
    "                user_vec_norm = user_vec / np.linalg.norm(user_vec)\n",
    "                movie_vec_norm = movie_vec / np.linalg.norm(movie_vec)\n",
    "                \n",
    "                # Calculate cosine similarity\n",
    "                cosine_sim = np.dot(user_vec_norm, movie_vec_norm)\n",
    "                \n",
    "                # Calculate gradients\n",
    "                user_grad = (1 - cosine_sim) * movie_vec_norm + reg_param * user_vec\n",
    "                movie_grad = (1 - cosine_sim) * user_vec_norm + reg_param * movie_vec\n",
    "    \n",
    "            user_features[user_id] -= learning_rate * user_grad\n",
    "            movie_features[movie_id] -= learning_rate * movie_grad\n",
    "    \n",
    "    return user_features, movie_features\n",
    "\n",
    "def evaluate_model(test_mat, user_features, movie_features, objective_func='mse'):\n",
    "    \"\"\"\n",
    "    Evaluate the collaborative filtering model on the test data with different objective functions.\n",
    "    \"\"\"\n",
    "    users = test_mat.row\n",
    "    movies = test_mat.col\n",
    "    ratings = test_mat.data\n",
    "    num_pts = len(users)\n",
    "    errors = np.empty(num_pts)\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        user_id, movie_id, actual_rating = users[i], movies[i], ratings[i]\n",
    "        predicted_rating = np.dot(user_features[user_id], movie_features[movie_id])\n",
    "\n",
    "        if objective_func == 'mse':\n",
    "            errors[i] = (actual_rating - predicted_rating) ** 2\n",
    "        elif objective_func == 'mae':\n",
    "            errors[i] = abs(actual_rating - predicted_rating)\n",
    "        elif objective_func == 'logistic':\n",
    "            errors[i] = -actual_rating * np.log(predicted_rating) - (1 - actual_rating) * np.log(1 - predicted_rating)\n",
    "        elif objective_func == 'nuclear_norm':\n",
    "            errors[i] = (actual_rating - predicted_rating) ** 2\n",
    "        elif objective_func == 'cosine_sim':\n",
    "            user_vec = user_features[user_id]\n",
    "            movie_vec = movie_features[movie_id]\n",
    "            \n",
    "            # Normalize user and movie vectors\n",
    "            user_vec_norm = user_vec / np.linalg.norm(user_vec)\n",
    "            movie_vec_norm = movie_vec / np.linalg.norm(movie_vec)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            cosine_sim = np.dot(user_vec_norm, movie_vec_norm)\n",
    "            \n",
    "            # Calculate error based on cosine similarity\n",
    "            errors[i] = 1 - cosine_sim\n",
    "\n",
    "    if objective_func == 'mse' or objective_func == 'nuclear_norm':\n",
    "        return np.sqrt(np.mean(errors))\n",
    "    elif objective_func == 'mae' or objective_func == 'logistic' or objective_func == 'cosine_sim':\n",
    "        return np.mean(errors)\n",
    "\n",
    "objective_functions = ['mse', 'mae', 'logistic', 'nuclear_norm', 'cosine_sim']\n",
    "\n",
    "for objective_func in objective_functions:\n",
    "    user_features, movie_features = collaborative_filtering(train_mat, num_latent_features=5, num_iterations=25, learning_rate=0.001, reg_param=0.01, nuclear_norm_param=0.001, objective_func=objective_func)\n",
    "    performance_metric = evaluate_model(test_mat, user_features, movie_features, objective_func=objective_func)\n",
    "    print(f\"Objective function: {objective_func}, Performance metric: {performance_metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
